{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**라이브러리 호출**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**데이터 불러오기 및 데이터 컬럼확인** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1955 entries, 1 to 1955\n",
      "Data columns (total 19 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Age                       1861 non-null   float64\n",
      " 1   TypeofContact             1945 non-null   object \n",
      " 2   CityTier                  1955 non-null   int64  \n",
      " 3   DurationOfPitch           1853 non-null   float64\n",
      " 4   Occupation                1955 non-null   object \n",
      " 5   Gender                    1955 non-null   object \n",
      " 6   NumberOfPersonVisiting    1955 non-null   int64  \n",
      " 7   NumberOfFollowups         1942 non-null   float64\n",
      " 8   ProductPitched            1955 non-null   object \n",
      " 9   PreferredPropertyStar     1945 non-null   float64\n",
      " 10  MaritalStatus             1955 non-null   object \n",
      " 11  NumberOfTrips             1898 non-null   float64\n",
      " 12  Passport                  1955 non-null   int64  \n",
      " 13  PitchSatisfactionScore    1955 non-null   int64  \n",
      " 14  OwnCar                    1955 non-null   int64  \n",
      " 15  NumberOfChildrenVisiting  1928 non-null   float64\n",
      " 16  Designation               1955 non-null   object \n",
      " 17  MonthlyIncome             1855 non-null   float64\n",
      " 18  ProdTaken                 1955 non-null   int64  \n",
      "dtypes: float64(7), int64(6), object(6)\n",
      "memory usage: 305.5+ KB\n"
     ]
    }
   ],
   "source": [
    "path = './_data/travel/' # \".은 현재 폴더\"\n",
    "train_set = pd.read_csv(path + 'train.csv',\n",
    "                        index_col=0)\n",
    "test_set = pd.read_csv(path + 'test.csv', \n",
    "                       index_col=0)\n",
    "\n",
    "\n",
    "\n",
    "train_set.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**결측치 처리 & 전처리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['TypeofContact'].fillna('Self Enquiry', inplace=True)\n",
    "test_set['TypeofContact'].fillna('Self Enquiry', inplace=True)\n",
    "train_set['Age'].fillna(train_set.groupby('Designation')['Age'].transform('mean'), inplace=True)\n",
    "test_set['Age'].fillna(test_set.groupby('Designation')['Age'].transform('mean'), inplace=True)\n",
    "train_set['Age']=np.round(train_set['Age'],0).astype(int)\n",
    "test_set['Age']=np.round(test_set['Age'],0).astype(int)\n",
    "\n",
    "train_set['MonthlyIncome'].fillna(train_set.groupby('Designation')['MonthlyIncome'].transform('mean'), inplace=True)\n",
    "test_set['MonthlyIncome'].fillna(test_set.groupby('Designation')['MonthlyIncome'].transform('mean'), inplace=True)\n",
    "print(train_set.describe) #(1955, 19)\n",
    "print(train_set[train_set['MonthlyIncome'].notnull()].groupby(['Designation'])['MonthlyIncome'].mean())\n",
    "\n",
    "train_set['NumberOfChildrenVisiting'].fillna(train_set.groupby('MaritalStatus')['NumberOfChildrenVisiting'].transform('mean'), inplace=True)\n",
    "test_set['NumberOfChildrenVisiting'].fillna(test_set.groupby('MaritalStatus')['NumberOfChildrenVisiting'].transform('mean'), inplace=True)\n",
    "train_set['NumberOfFollowups'].fillna(train_set.groupby('NumberOfChildrenVisiting')['NumberOfFollowups'].transform('mean'), inplace=True)\n",
    "test_set['NumberOfFollowups'].fillna(test_set.groupby('NumberOfChildrenVisiting')['NumberOfFollowups'].transform('mean'), inplace=True)\n",
    "# combine = [train_set,test_set]\n",
    "# for dataset in combine:    \n",
    "#     dataset.loc[ dataset['NumberOfChildrenVisiting'] < 1, 'NumberOfChildrenVisiting'] = 0\n",
    "#     dataset.loc[ dataset['NumberOfChildrenVisiting'] >= 1, 'NumberOfChildrenVisiting'] = 1\n",
    "# print(train_set[train_set['DurationOfPitch'].notnull()].groupby(['NumberOfChildrenVisiting'])['DurationOfPitch'].mean())\n",
    "# print(train_set.isnull().sum()) \n",
    "\n",
    "train_set['DurationOfPitch']=train_set['DurationOfPitch'].fillna(0)\n",
    "test_set['DurationOfPitch']=test_set['DurationOfPitch'].fillna(0)\n",
    "\n",
    "\n",
    "print(train_set[train_set['DurationOfPitch'].notnull()].groupby(['NumberOfChildrenVisiting'])['DurationOfPitch'].mean())\n",
    "\n",
    "\n",
    "train_set['PreferredPropertyStar'].fillna(train_set.groupby('Occupation')['PreferredPropertyStar'].transform('mean'), inplace=True)\n",
    "test_set['PreferredPropertyStar'].fillna(test_set.groupby('Occupation')['PreferredPropertyStar'].transform('mean'), inplace=True)\n",
    "print(train_set[train_set['PreferredPropertyStar'].notnull()].groupby(['ProdTaken'])['PreferredPropertyStar'].mean())\n",
    "\n",
    "\n",
    "combine = [train_set,test_set]\n",
    "for dataset in combine:    \n",
    "    dataset.loc[ dataset['Age'] <= 26.6, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 26.6) & (dataset['Age'] <= 35.2), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 35.2) & (dataset['Age'] <= 43.8), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 43.8) & (dataset['Age'] <= 52.4), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 52.4, 'Age'] = 4\n",
    "# train_set = train_set.drop(['AgeBand'], axis=1)\n",
    "# print(train_set[train_set['NumberOfTrips'].notnull()].groupby(['DurationOfPitch'])['PreferredPropertyStar'].mean())\n",
    "train_set['NumberOfTrips'].fillna(train_set.groupby('DurationOfPitch')['NumberOfTrips'].transform('mean'), inplace=True)\n",
    "test_set['NumberOfTrips'].fillna(test_set.groupby('DurationOfPitch')['NumberOfTrips'].transform('mean'), inplace=True)\n",
    "# print(train_set[train_set['NumberOfChildrenVisiting'].notnull()].groupby(['MaritalStatus'])['NumberOfChildrenVisiting'].mean())\n",
    "\n",
    "\n",
    "\n",
    "train_set.loc[ train_set['Gender'] =='Fe Male' , 'Gender'] = 'Female'\n",
    "test_set.loc[ test_set['Gender'] =='Fe Male' , 'Gender'] = 'Female'\n",
    "cols = ['TypeofContact','Occupation','Gender','ProductPitched','MaritalStatus','Designation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "연락처 유형 ,나이 ,월소득 등등 불필요하다고 느낀것들은 0처리 또는 제거했습니돴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**라벨 인코더 해주기 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "for col in tqdm_notebook(cols):\n",
    "    le = LabelEncoder()\n",
    "    train_set[col]=le.fit_transform(train_set[col])\n",
    "    test_set[col]=le.fit_transform(test_set[col])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1~3 사분위해서  이상치 위치확인하고 이상치 0 만들었습니다. ** (5분위 까지는 못했음ㅜㅋㅋ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def outliers(data_out):\n",
    "    quartile_1, q2 , quartile_3 = np.percentile(data_out,\n",
    "                                               [25,50,75]) #\n",
    "    print(\"1 : \",quartile_1) # 25% 위치인수를 기점으로 사이에 값을 구함\n",
    "    print(\"q2 : \",q2) # \n",
    "    print(\"3 : \",quartile_3) # 75% 위치인수를 기점으로 사이에 값을 구함\n",
    "    iqr =quartile_3-quartile_1  # 75% -25%\n",
    "    print(\"Iqr :\" ,iqr)\n",
    "    lower_bound = quartile_1 - (iqr * 1.5)\n",
    "    upper_bound = quartile_3 + (iqr * 1.5)\n",
    "    return np.where((data_out>upper_bound)|\n",
    "                    (data_out<lower_bound))\n",
    "                     \n",
    "                           \n",
    "DurationOfPitch_out_index= outliers(train_set['DurationOfPitch'])[0] #44\n",
    "Gender_out_index= outliers(train_set['Gender'])[0] # 0\n",
    "NumberOfPersonVisiting_out_index= outliers(train_set['NumberOfPersonVisiting'])[0] # 1\n",
    "NumberOfFollowups_out_index= outliers(train_set['NumberOfFollowups'])[0] # 0\n",
    "ProductPitched_index= outliers(train_set['ProductPitched'])[0] # 0\n",
    "PreferredPropertyStar_out_index= outliers(train_set['PreferredPropertyStar'])[0]  # 0\n",
    "MaritalStatus_out_index= outliers(train_set['MaritalStatus'])[0] # 0\n",
    "NumberOfTrips_out_index= outliers(train_set['NumberOfTrips'])[0] # 38\n",
    "Passport_out_index= outliers(train_set['Passport'])[0] # 0\n",
    "PitchSatisfactionScore_out_index= outliers(train_set['PitchSatisfactionScore'])[0] # 0\n",
    "OwnCar_out_index= outliers(train_set['OwnCar'])[0] # 0\n",
    "NumberOfChildrenVisiting_out_index= outliers(train_set['NumberOfChildrenVisiting'])[0] # 0\n",
    "Designation_out_index= outliers(train_set['Designation'])[0] # 89\n",
    "MonthlyIncome_out_index= outliers(train_set['MonthlyIncome'])[0] # 138\n",
    "\n",
    "lead_outlier_index = np.concatenate((#Age_out_index,                     \n",
    "                                      DurationOfPitch_out_index,               \n",
    "                              \n",
    "                                     ),axis=None)\n",
    "print(len(lead_outlier_index)) #577\n",
    "\n",
    "lead_not_outlier_index = []\n",
    "for i in train_set.index:\n",
    "    if i not in lead_outlier_index :\n",
    "        lead_not_outlier_index.append(i)\n",
    "train_set_clean = train_set.loc[lead_not_outlier_index]      \n",
    "train_set_clean = train_set_clean.reset_index(drop=True)\n",
    "# print(train_set_clean)\n",
    "x = train_set_clean.drop(['ProdTaken',\n",
    "                          'NumberOfChildrenVisiting',\n",
    "                          'NumberOfPersonVisiting',\n",
    "                          'OwnCar', \n",
    "                          'MonthlyIncome', \n",
    "                          'NumberOfFollowups',\n",
    "                          'Designation'\n",
    "                          ], axis=1)\n",
    "# x = train_set_clean.drop(['ProdTaken'], axis=1)\n",
    "test_set = test_set.drop(['NumberOfChildrenVisiting',\n",
    "                          'NumberOfPersonVisiting',\n",
    "                          'OwnCar', \n",
    "                          'MonthlyIncome', \n",
    "                          'NumberOfFollowups',\n",
    "                          'Designation'\n",
    "                          ], axis=1)\n",
    "y = train_set_clean['ProdTaken']\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**catboost모델구성 및 KFOLD 넣고 파라미터튜닝까지(중요!)**\n",
    "cat부스트 디폴트 메소드로 사용해도 좋지만 메소드 값들 바꿔가면서 해봤어요 디폴트 썻으면 일등했을지도 ㅜㅋㅋ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,train_size=0.91,shuffle=True,random_state=123, stratify=y)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# 2. 모델\n",
    "\n",
    "n_splits = 6\n",
    "\n",
    "kfold = KFold(n_splits=n_splits,shuffle=True,random_state=77)\n",
    "\n",
    "cat_paramets = {\"learning_rate\" : [0.1209090790920735],\n",
    "                'depth' : [8],\n",
    "                'od_pval' : [0.2326844395451],\n",
    "                'model_size_reg': [0.3250614063442997],\n",
    "                'fold_permutation_block': [142],\n",
    "                'l2_leaf_reg' :[6.53517551183905427]}\n",
    "cat = CatBoostClassifier(random_state=1234,verbose=False,n_estimators=1324)\n",
    "model = RandomizedSearchCV(cat,cat_paramets,cv=kfold,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgb 랑 cat 둘다 써본결과 cat이 미세하게 좋았음 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "start_time = time.time()\n",
    "model.fit(x_train,y_train)   \n",
    "end_time = time.time()-start_time \n",
    "y_predict = model.predict(x_test)\n",
    "results = accuracy_score(y_test,y_predict)\n",
    "print('파라미터 : ',model.best_params_)\n",
    "print('점수 : ',model.best_score_)\n",
    "print('에큐러시 :',results)\n",
    "print('시간 :',end_time)\n",
    "\n",
    "model.fit(x,y)\n",
    "y_summit = model.predict(test_set)\n",
    "y_summit = np.round(y_summit,0)\n",
    "submission = pd.read_csv(path + 'sample_submission.csv',#\n",
    "                      )\n",
    "submission['ProdTaken'] = y_summit\n",
    "\n",
    "submission.to_csv('dacon.csv',index=False)\n",
    "\n",
    "# acc : 0.9673202614379085\n",
    "# acc : 0.9607843137254902\n",
    "# acc : 0.9644970414201184"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 코드공유를 마무리하겠습니다. 감사합니다 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tf282gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "df88f286fcd5f82d6263e3a1df7af676711953b4f295dd9e8586b691ec36fe66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
